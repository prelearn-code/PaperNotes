---
title: Enabling Secure and Efficient Decentralized Storage Auditing With Blockchain
year: 2022-01-01
venue: IEEE Transactions on Dependable and Secure Computing
field:
  - Authentication
pdf: "[[Enabling Secure and Efficient Decentralized Storage Auditing With Blockchain]]"
Read_date: 2025-11-28
detailes:
---
# 0.背景


# 论文
**论文真问题**  
在区块链辅助的去中心化存储审计中，现有基于同态标签/PoR 的方案在公开链上泄露过多审计轨迹，使得理性存储节点可以“搭链白嫖”恢复数据并节省本地存储，从而在保持审计通过的同时破坏存储完整性，本文针对这一被忽视的“存储 freeriding/数据恢复”问题，在保证链上开销可接受的前提下给出缓解方案。

---

## 方案背景

### 领域瓶颈

1. **Merkle 树与 SNARK 审计各有结构性缺陷**
    
    - Merkle 树：挑战随机性有限，“最终会耗尽新鲜块”，因此不适合长期存储；每次证明都要暴露原始数据块以打开 Merkle root，使**数据恢复风险高**，尤其在审计轮数增多时更严重。
    - SNARK（如 Filecoin）方案：虽然证明短、链上验证快，但主要瓶颈是**预处理与证明生成的巨大开销**，包括需要可信设置（结构化参考字符串）以及重型 prover 计算，官方 Filecoin 项目也承认这是进一步部署的障碍。
	    - 其中的公共参数都2GB,并且还要把数据预处理为一种特定的格式。
    - 默克尔树：
      ```mermaid
	       graph TD
		       root_h[root]
		       h1[H1]
		       h2[H2]
		       h3[H3]
		       h4[H4]
		       h5[H5]
		       h6[H6]
		       b1[B1]
		       b2[B2]
		       b3[B3]
		       b4[B4]
		 %% 图之间的关系
		 root_h --> h1
		 root_h -->h2
		 h1 --> h3
		 h1 --> h4
		 h2 --> h5
		 h2 --> h6
		 h3 ---- b1
		 h4 ---- b2
		 h5 ---- b3
		 h6 ---- b4
      ```
2. **传统 PoR/PDP 方案与 DSN/区块链环境不兼容**
    
    - 许多 HLA（同态线性认证）方案在 DSN 环境下要么需要额外存储预处理数据 F̃，要么需要较大的通信开销，难以在去中心化场景中落地。
	    - 多为私密验证时使用，并且，存储的信息比较多，未考虑永久上链。
    - 这些方案的安全模型通常只考虑**单轮交互**，并未考虑“所有审计证明永久公开存储在区块链上”的现实，导致在多轮、多年审计周期中，链上审计轨迹可以被系统性利用。
        

### 作者动机

- 作者在前一版工作中已经处理了“利用链上审计轨迹进行**非授权数据恢复**”的问题，但随后发现：
    
    > “还必须处理另一个源自去中心化范式中普遍外包行为的**未预见威胁**，该安全问题使存储节点能够破坏审计完整性。”
    > 这是一个源自去中心化环境、基于外包行为产生的新型攻击：存储节点可以在“没有真正存储文件”的情况下，依然通过所有审计。在去中心化存储网络中，节点为了节省成本，会把应该自己保存的数据外包给别人、甚至直接依赖链上历史审计记录，从而破坏审计完整性。
    
- 在 DSN 中，参与方是**理性经济行为者**，会利用区块链“零边际成本存储”和外包策略最大化利润，因此需要一个在理性博弈下仍能维持审计完整性的框架，并兼顾：
    
    1. 强数据完整性（即便有公开链）；
        
    2. 链上验证成本可负担；
        
    3. 存储节点端证明生成可扩展。
        

---

## 创新点

> 以下仅列“作者实际做到的”内容，不含宣称但未实现之点。

### 1. [核心] 链上审计轨迹下的“存储 freeriding / 数据恢复”攻击模型

**突破点**：首次在通用区块链 + PoR 审计框架下，系统分析存储节点如何利用**历史链上审计证明**节省本地存储却仍能通过未来审计，并给出两类具体策略及量化分析。

- **策略 I：基于单轮新鲜挑战的插值恢复**
    
    - 将每轮审计中 `(r, f_Ũ_k(r))` 视作目标 chunk 的“奇偶块（parity block）”；
        
    - 若针对某数据块只缺失一个系数，对同一 chunk 的多个点进行多项式插值即可恢复整 chunk；
        
    - 这样只需记录“可恢复块的位置元数据”，而不必存大规模群元素。
        
- **策略 II：多轮重复挑战下的多点重用**
    
    - 当后续轮次挑战集中在先前已挑战的 chunk 上时，存储节点可以累积多个 `(r_i, f_Ũ_k(r_i))` 对；
        
    - 在挑战次数足够多时，可完全从链上审计轨迹恢复整个 chunk，无需本地存储。
        
- **量化分析**：
    
    - 定义“所有 chunk 至少被挑战一次”的轮数随机变量 X，并通过尾和公式和容斥原理推导其期望 `L_predict`，给出闭式表达式：  
        $L_{\text{predict}} = {d \choose k} \sum_{t=1}^d (-1)^{t+1} {d \choose t} \left( {d \choose k} - {d-t \choose k} \right)^{-1}$
    - 实验（图 8，第 13 页）给出仿真值 (L_{\text{real}})：
        
        - 32 MB 数据仅需约 10 轮审计就进入“每 chunk 至少被挑战一次”的区间；
            
        - 较大数据（如 1 GB）需要数百轮，但 freeriding 仍有大量可利用空间。
            
    - 图 9 显示：不同数据规模下，**额外元数据存储开销 / 节省存储量**的比例近似相同且较低，说明 freeriding 在经济上极具吸引力。
        

**关键证据**：Section 5.2–5.3 对策略 I/II 与 `L_predict` 推导；Section 7.3 图 8–9 的仿真实验。

---

### 2. [核心] 基于 KZG 多项式承诺的轻量级链上审计协议

**突破点**：将传统 HLA 型 PoR 重构为**以 KZG 多项式承诺为核心**的“chunk 级聚合+单点验证”结构，大幅降低数据拥有者预处理开销与链上验证成本，同时适配区块链环境。

- **Chunk 聚合建模（图 2，第 6 页）**
    
    - 将编码后的数据 F̃ 视为矩阵 $(m_{i,j})$，行数 s、列数 d；
        
    - 每 s 个块形成一个 chunk，作为多项式 $(f_{\vec{m}_j}(X))$ 的系数；
        
    - 对每个 chunk 计算 KZG 承诺作为 tag，减少辅助数据大小与预处理时间。
        
- **Tag 设计 = KZG 承诺 + BLS 签名**
    
    - 私钥 `sk=(x,a)`，公钥 $pk=(v=g^x, d=g^{xa}, {g^{a^j}})$；
        
    - 对 chunk j：  
        $s_j = \left( H(\text{name} | j) \cdot g^{f_{\vec{m}_j}(a)} \right)^x$
        
    - 存储节点可用  
        $e(s_j, g) \stackrel{?}{=} e\big(H(\text{name}|j)\cdot g^{f_{\vec{m}_j}(a)}, v\big)$
        验证 tag 生成正确。
        
- **审计证明聚合与验证（式 (1)）**
    
    - challenge：from 链上随机种子，经 PRF 生成索引集合 C 和系数 ν_j；
        
    - 存储节点计算：
        
        - 聚合 tag：$(\sigma = \prod_{(j,\nu_j)\in C} s_j^{\nu_j})$
            
        - 聚合多项式：$(f_{U_k}(X) = \sum_{(j,\nu_j)\in C} \nu_j f_{\vec{m}_j}(X))$
            
        - 评价点 r 与值 $y = f_U_k(r)$；
            
        - 余式多项式承诺 c，用于验证 $f_U_k(a)-f_U_k(r) = (a-r)·h(X)$ 关系；
            
    - 合约执行式 (1)：  
        $e(\phi, v) \cdot e(c, d\cdot v^{-r}) \stackrel{?}{=} e(\sigma, g)\cdot e(g^{-y}, v)$  
        
    - 仅需 **4 次双线性对运算** 完成验证。
        

**关键证据**：Section 4.2–4.3 对 KZG 介绍，Section 5.1 的 GenKey / GenTag / VeriTag / Prove / Verify 定义。

---

### 3. [核心] 定制化零知识随机掩码 + 链上掩码唯一性检测的 freeriding 缓解方案

**突破点**：不是简单“加 ZK-SNARK”，而是通过**线性随机掩码 + 合约内 Query 检查 R 是否重复**，在保持同一 PoR 结构的前提下，抑制存储节点重复使用掩码、利用线性方程组恢复数据的能力，且额外链上成本受控（约增加 10–15%）。

- **随机掩码 ZKP 版本**
    
    - 存储节点选 z∈Z_p，计算 (R = e(g, v)^z ∈ G_T)，再令 ζ = H₀(R) 作为最终掩码；
        
    - 用 ζ 替换原始 y：  
        $y' = \zeta \cdot f_{U_k}(r) + \zeta$  
        
        
    - 证明变为 (R, σ, y′, ψ)，验证式 (2)：  
        $e(\phi^\zeta, v)\cdot e(\psi^\zeta, d\cdot v^{-r})\stackrel{?}{=}e(\sigma^\zeta, g)\cdot e(g^{-y'}, v)$  
        
    - 这样链上观察者无法从证明中恢复 f_U_k(r)，阻止“离线数据恢复”。
        
- **掩码唯一性链上检查（图 5，第 10 页）**
    
    - 合约维护 mapping(address⇒address list) 记录历史 R；
        
    - 函数 `Query(R)` 对最近 `num` 个 R 做线性扫描，若发现重复则审计失败；
        
    - 计数器 `cnt` 超过阈值 `num` 后，强制数据拥有者重新预处理数据并更新 tags，实现**审计轨迹“更新”**。
        
- **对理性外包的博弈分析（Section 6.2）**
    
    - 假设存储资源比带宽/计算更稀缺；
        
    - 通过强制掩码非重复，使“继续外包并重用掩码”的策略需要更多链外存储/协调，降低其收益，从而实现一种**启发式 weak non-outsourceability**。
        

**关键证据**：Section 5.3 的 ZKP 改造与式 (2)、图 5 的合约伪代码、Section 6.2 的理性博弈讨论。

---

### 4. [辅助] 端到端原型实现与系统级性能优化

**要点**：不仅在理论上给出协议，还在 Tahoe-LAFS + 以太坊私链上完成原型，并通过预编译双线性运算 opcode 优化链上性能，给出与 VDS、ZKCSP、Filecoin 的**量化对比**。

- **工程设计**
    
    - 使用 Tahoe-LAFS 作为去中心化存储底层，Ethereum 作为仲裁链；
        
    - 由于 EVM 不原生支持 pairing，作者用 C/C++（~1500 行）基于 mcl 库预编译双线性算子，在私链内引入高效 opcode；
        
    - 选择 BN254 曲线以平衡安全与效率。
        
- **对比结果（表 3，第 13 页，1 GB 文件）**：
    
    - Filecoin：预处理约 870 s，公共参数约 2 GB，证明生成 10.5 s，内存 1 GB，验证 24 ms，对应费用约 0.44 USD；
        
    - 本文主方案：预处理 118 s，公共参数约 5 KB，证明生成 46 ms，内存约 3 MB，证明大小 288 bytes，验证 7 ms，对应费用约 0.21 USD。
        

---

## 方案架构

### 核心流程（审计生命周期）

**输入 → 处理 → 输出**（结合图 1、3，第 5/7 页）

1. **数据准备与存储**
    
    - 输入：用户原始数据 F；
        
    - 处理：
        
        - 客户端本地对 F 进行对称加密；
            
        - 进行分块 + 纠删编码得到 F̃；
            
        - 将 F̃ 按 s 块划分为 d 个 chunk，映射为多项式 (f_{\vec{m}_j}(X))。
            
    - 输出：编码数据块 (m_{i,j}) 发送给存储节点。
        
2. **标签生成与上链参数**
    
    - 输入：编码数据 blocks、随机文件标识 name；
        
    - 处理：运行 GenKey 得到 sk=(x,a)、pk=(v,g^{xa},g^{a^j})；运行 GenTag 生成每 chunk 的 tag s_j；存储节点用 VeriTag 验证标签正确性；
        
    - 输出：公钥 pk 和必要元数据写入审计合约状态。
        
3. **周期性审计**
    
    - 输入：链上随机性（随机信标或节点网络）、当前轮计数；
        
    - 处理：
        
        - 合约/节点从随机种子通过 PRF 生成挑战索引集合 C 和系数 ν_j；
            
        - 存储节点从本地数据计算聚合 tag σ、聚合多项式 f_U_k、评价点 r 和 f_U_k(r)，以及 KZG 见证 c；
            
        - ZKP 版本下，再生成随机掩码 (R, y′) 和 ψ；
            
        - 将证明发送到链上触发 Verify + Query。
            
    - 输出：
        
        - 合约给出当前轮 accept/reject；
            
        - 到期时，合约根据所有轮次的审计结果自动结算罚金/存储费。
            

### 关键设计机制

1. **多项式承诺驱动的 homomorphic tag 机制**
    
    - 每个 chunk 只对应一个 KZG 承诺 + BLS 签名，审计时可对多个 chunk 做线性组合，证明大小与挑战数 k 无关；
        
    - 通过式 (1)/(2) 的 pairing 等式，将“数据线性组合正确性 + tag 签名正确性”合并为一次多对等式检查，压缩链上验证成本。
        
2. **审计随机性生成与挑战派生**
    
    - 论文仅说明使用“独立运行节点网络生成的分布式随机性”或随机信标框架，[原文未详述]具体协议；
        
    - 从随机种子通过两种 PRF 派生：
        
        - C₁ ⇒ {0,1}^λ 生成 chunk 索引集合 I⊂{1,…,d}；
            
        - C₂ ⇒ {0,1}^λ 生成权重向量 {ν_j}；
            
    - 确保每轮挑战位置和权重不可预测。
        
3. **链上掩码唯一性检测（Query 机制）**
    
    - 合约保存历史 R 列表；
        
    - 对于每轮新 R：
        
        - 调用 `Query(R)` 在最近 `num` 个记录中查重；
            
        - 若重复则立即 `broadcast("fail")` 并锁定质押；
            
        - 若不重复则增加计数器 cnt，继续 Verify；
            
    - 当 `cnt ≥ num` 时，强制触发“重新预处理”，要求数据拥有者更新 tags，从而定期刷新审计轨迹，限制长期数据恢复的可行性。
        
4. **存储 freeriding 量化与参数选型**
    
    - 通过 L_predict/L_real 与额外元数据占比（图 8–9）分析 freeriding 的收益区间，用于选择：
        
        - chunk 大小（文中建议中等 32 KB）；
            
        - 审计轮数与更新周期（通过 num 控制）；
            
        - 挑战数 k（实验中采用 300 或 460，对应不同检测概率）。
            

---

## 实验环境

### 硬件/平台

- **存储节点 & 矿工**：
    
    - Intel Xeon E-2174G ×4 @ 3.80 GHz，Ubuntu Server 18.04 LTS。
        
- **数据拥有者客户端**：
    
    - Intel Core i7-8700K ×6 @ 3.70 GHz，桌面系统。
        
- **软件栈**：
    
    - 去中心化存储：Tahoe-LAFS；
        
    - 区块链：以太坊模板搭建的私链（3 个矿工 + 1 存储节点 + 1 客户端）；
        
    - pairing：mcl 库 + 自定义预编译 opcode。
        

### 基线对比方法

表 3（第 13 页）列出 4 类可部署的去中心化存储审计方案：

1. **VDS [27]**：基于 accumulator 的可增量向量承诺与 PoR 方案；[原文未明确标注是否 SOTA]。
    
2. **ZKCSP [55]**：基于通用 zkSNARK 的零知识 contingent payments 框架；[原文未明确标注是否 SOTA]。
    
3. **Filecoin [13,29]**：工业级 SNARK + PoST 方案；[原文未明确标注是否 SOTA]。
    
4. **本文主方案**：KZG + homomorphic tag + 定制 ZKP。
    

（论文未使用“state-of-the-art”标签来评价对比对象，因此其 SOTA 状态标记为[原文未详述]。）

### 评估指标

**主指标（以链上成本为主）**

- 单轮审计 gas 消耗（含/不含 ZKP 以及 Query）；
    
- 合约部署 + 多轮审计后的摊销 gas 成本；
    
- 基于 gas 与 ETH/USD 汇率估算的**总审计费用**（美元），随存储时长变化；
    
- 链上验证时间（5–9 ms 范围插值）。
    

**次指标**

- 预处理阶段：
    
    - 公钥（审计参数）大小 vs chunk 大小（图 6）；
        
    - 数据预处理时间 vs 文件大小和 chunk 大小（图 7）。
        
- 存储 freeriding：
    
    - 达到“所有 chunk 至少被挑战一次”的轮数 L_real vs L_predict（图 8）；
        
    - 索引元数据额外存储占比（图 9）。
        
- 存储节点端：
    
    - 证明生成时间 vs chunk 大小、检测概率标准（95% vs 99%，图 13）；
        
    - 引入 ZKP 前后证明生成时间对比（图 14）。
        

### 关键结果（用数据说话）

1. **整体性能对比（表 3，1 GB 文件）**
    
    - **Filecoin**：
        
        - 预处理时间 ~ 870 s；
            
        - 公共参数大小 ~ 2 GB；
            
        - 证明生成 10.5 s；
            
        - 内存占用 1 GB；
            
        - 证明大小 384 bytes；
            
        - 验证时间 24 ms；
            
        - 验证费用约 0.44 USD。
            
    - **本文主方案**：
        
        - 预处理时间 118 s；
            
        - 公共参数大小 ~ 5 KB；
            
        - 证明生成 46 ms；
            
        - 内存占用 3 MB；
            
        - 证明大小 288 bytes；
            
        - 验证时间 7 ms；
            
        - 验证费用约 0.21 USD。  
            → 在相近证明大小与更短验证时间下，将 prover 预处理和内存开销降低一个数量级以上。
            
2. **预处理阶段权衡（图 6–7）**
    
    - chunk=256 KB 时，单用户公钥上链需要 >250 KB 存储，约需 200 个满 gas 区块才能提交，链上成本不可接受；
        
    - chunk=32 KB 时，1 GB 数据预处理（不含链上提交）耗时超过 40 s（图 7），而表 3 中整体预处理时间为 118 s；
        
    - 因此作者选择 32 KB 作为折衷，保证公钥大小约 5 KB。
        
3. **存储 freeriding 可行性（图 8–9）**
    
    - 对 32 MB 数据，约 10 轮审计后就达到所有 chunk 至少被挑战一次的区间，此后可主要采用策略 II 重用链上审计轨迹；
        
    - 对 64 MB、160 MB 等更大数据，L_real 逐步上升到数十甚至数百轮；
        
    - 图 9 显示：额外索引元数据/节省存储的比例在不同数据规模下维持在同一数量级（曲线在 2%–10% 区间内变化），表明 freeriding 在经济上具有稳定吸引力。
        
4. **ZKP 适配带来的链上开销增量（图 10–12）**
    
    - 图 10：对不同 pairing 验证时间（5–9 ms）插值，加入 ZKP 后单轮审计 gas 成本略增，但总体处于相同量级；
        
    - 图 11：当审计轮数较多时，合约部署+Query 操作摊销后，单轮平均 gas 成本明显下降；
        
    - 图 12：对于 50、200、500、800 天的存储时长，考虑 ETH 价格后估算的总显性审计成本显示：
        
        - ZKP 版本相较基线方案总体费用只增加约 **10–15%**；
            
        - 总费用数量级与中心化云存储的存储费用相当，但内含显式审计成本。
            
5. **存储节点端证明生成开销（图 13–14）**
    
    - 块大小从 4 KB 增至 256 KB 时，证明生成时间近似线性增长；
        
    - 在 chunk=32 KB 且挑战数 k=300（检测 1% 损坏概率≥95%）时，单个证明生成时间 <150 ms；
        
    - 将检测标准提升至 99%（k=460）时，证明时间增加 <20%；
        
    - 引入 ZKP 后的证明生成时间增量远小于提高检测标准带来的增量。
        

---

## 致命局限

1. **仅支持静态数据，动态可更新存储未解决**
    
    - 作者明确指出当前方案仅面向静态数据（如长期归档），动态数据审计在 DSN 中仍然是“开放挑战”，现有云环境下的动态 PoR 方案无法直接用于链上审计，原因在于链上开销问题。计划未来：
        
        - 重新定义适用于去中心化环境的“动态审计”安全模型；
            
        - 重新设计数据索引结构以支持更新和回滚；
            
        - 考虑与当前静态方案的向后兼容。
            
2. **freeriding 对策为启发式，弱非外包性依赖经济假设**
    
    - Section 6.2 中，weak non-outsourceability 的实现依赖假设“存储容量比其他资源更有价值”，以及存储节点会因掩码唯一性检查而减少外包倾向；
        
    - 作者也明确称其为“启发式对策（heuristic countermeasure）”，并未给出形式化的博弈论证明，意味着在非标准经济环境或成本结构变化时，对策可能失效。
        
3. **可用性与部署层面的不足**
    
    - 作者承认尚未系统优化可用性：
        
        - 数据拥有者端的预处理成本仍然不低；
            
        - 存储节点端的证明生成在大规模多租户环境下的扩展性需要进一步工程化。
            
    - 未来工作将专门针对“降低预处理开销、增强证明生成的可扩展性”展开，当前原型更多是性能上可行但未完全工业化的研究系统。
        

---
